{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U bitsandbytes\n!pip install -q -U git+https://github.com/huggingface/transformers.git\n!pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install -q -U git+https://github.com/huggingface/accelerate.git\n! pip install datasets\n! pip install torch","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:33:50.806210Z","iopub.execute_input":"2023-08-30T17:33:50.806909Z","iopub.status.idle":"2023-08-30T17:36:04.305059Z","shell.execute_reply.started":"2023-08-30T17:33:50.806873Z","shell.execute_reply":"2023-08-30T17:36:04.303731Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.14.4.dev0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install fasttext","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:36:04.308196Z","iopub.execute_input":"2023-08-30T17:36:04.308823Z","iopub.status.idle":"2023-08-30T17:36:15.472472Z","shell.execute_reply.started":"2023-08-30T17:36:04.308770Z","shell.execute_reply":"2023-08-30T17:36:15.471289Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Requirement already satisfied: fasttext in /opt/conda/lib/python3.10/site-packages (0.9.2)\nRequirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.10/site-packages (from fasttext) (2.10.4)\nRequirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from fasttext) (59.8.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fasttext) (1.23.5)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom transformers import BitsAndBytesConfig, AutoConfig, AutoModelForCausalLM, AutoModelWithLMHead\nfrom transformers import GenerationConfig\nimport torch\nfrom accelerate import init_empty_weights, infer_auto_device_map\nimport re\nfrom functools import reduce","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:36:15.476570Z","iopub.execute_input":"2023-08-30T17:36:15.476893Z","iopub.status.idle":"2023-08-30T17:36:15.482275Z","shell.execute_reply.started":"2023-08-30T17:36:15.476864Z","shell.execute_reply":"2023-08-30T17:36:15.481389Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\ndataset_1 = load_dataset(\"codeparrot/xlcost-text-to-code\", \"Python-program-level\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset_1['train'][24]['text'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset_1['train'][24]['code'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# special tokens for prompting\nsystem_token = \"<SYSTEM_TASK:>\"\nuser_token = \"<USER_TASK:>\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_1(data):\n    text_prompts = list(map(lambda x: x.replace(' | ', ','), data['text']))\n    text_prompts = list(map(lambda x: x.replace(' \\n ', ','), data['text']))\n    prompt = ''\n    final_code = ''\n    final_text_prompt = []\n    final_code_prompt = []\n    code = data['code']\n    for i in range(len(text_prompts)):\n        prompt =  text_prompts[i]\n        new_prompt = ''\n        arr = prompt.split(';')\n        for i in range(len(arr)):\n# 2\n#             new_prompt = new_prompt + 'def ' + arr[i] + '\\b():' + '\\n\\t' + f'\"\"\"{arr[i]}\"\"\"' + '\\n'\n# 1\n#             new_prompt = new_prompt + 'def' + ' python' + '():' + '\\n\\t' + f'\"\"\"{arr[i]}\"\"\"' + '\\n'\n# 4\n#             new_prompt = new_prompt + 'def' + ' write_python_code' + '():' + '\\n\\t' + f'\"\"\"\\n\\t{arr[i]}\\n\\t\"\"\"' + '\\n\\n'\n# 5\n#             new_prompt = new_prompt + 'def' + ' write_python_code' + '():' + '\\n\\t' + f'\"\"\"{arr[i]}\"\"\"' + '\\n\\n'   \n# 3\n            new_prompt = new_prompt + 'def' + arr[i] + '():' + '\\n\\t' + f'#{arr[i]}' + '\\n'\n\n        code[i] = code[i].replace('NEW_LINE INDENT' , '\\n\\t')\n        code[i] = code[i].replace('NEW_LINE' , '\\n')\n        code[i] = code[i].replace('DEDENT' , '\\b')\n        code[i] = code[i].replace(' ( ' , '(')\n        code[i] = code[i].replace(' [ ', '[')\n        code[i] = code[i].replace('_ ', '_')\n        code[i] = code[i].replace('\" ', '\"')\n        final_code = code[i]\n        final_text_prompt.append(new_prompt)\n        final_code_prompt.append(final_code)\n    return {\n      'text_prompt' : final_text_prompt,\n      'code_prompt' : final_code_prompt\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_text_prompt = []\nfinal_code_prompt = []\nprompted_data_1 = dataset_1.map(process_1, batched = True, remove_columns = ['text', 'code'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompted_data_1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(prompted_data_1['train'][4]['text_prompt'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(prompted_data_1['train'][4]['code_prompt'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"code_lines = prompted_data_1['train'][10]['code_prompt'].split('\\n')\nfunc = ''\nfor i in range(len(code_lines)):\n    if 'def' in code_lines[i][:10]:\n        func = code_lines[i] + '\\n'\n        \nprint(func)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# special tokens for prompting\nsystem_token = \"<SYSTEM_TASK:>\"\nuser_token = \"<USER_TASK:>\"\nassistant_token = \"<ASSISTANT_TASK:>\"\nend_token = \"<END_TASK>\"\n\n\ntokenizer = AutoTokenizer.from_pretrained(\"codeparrot/codeparrot\",\n                                          additional_special_tokens = [\"<SYSTEM_TASK:>\", \"<USER_TASK:>\", \"<ASSISTANT_TASK:>\", \"<END_TASK>\"],\n                                          pad_token = \"<PAD>\",\n                                          )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"special_token_dict = tokenizer.special_tokens_map\nprint(special_token_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.add_special_tokens(special_token_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_length = 10000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(\"codeparrot/codeparrot\",\n                                    vocab_size=tokenizer.vocab_size,\n                                    bos_token_id=tokenizer.bos_token_id,\n                                    eos_token_id=tokenizer.eos_token_id,\n)\n\nwith init_empty_weights():\n    model = AutoModelForCausalLM.from_config(config)\n    \nprint(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device_map = infer_auto_device_map(model, no_split_module_classes = ['GPT2Block'])\nprint(device_map)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch \n\nnf4_config = BitsAndBytesConfig(\n   load_in_2bit=True,\n   bnb_4bit_quant_type=\"nf4\",\n   bnb_4bit_use_double_quant=True,\n   bnb_4bit_compute_dtype=torch.bfloat16\n)\n\n\nmodel_id = \"codeparrot/codeparrot\"\nmodel =AutoModelForCausalLM.from_pretrained(model_id,\n                                            config = config,\n                                            device_map=\"auto\",\n                                            quantization_config=nf4_config,\n                                            torch_dtype=torch.bfloat16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.resize_token_embeddings(len(tokenizer))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"add_prompt = '<SYSTEM_TASK:>\\nGiven the following code description, write Python code to implement the functionality described below\\n<END_TASK>\\n<USER_TASK:>\\nDescription:\\n'\nexp = prompted_data_1['train'][23]['text_prompt']\nexp1 = 'Write a pyhton code for each function as defined in comments\\n'\n# final_prompt = add_prompt + exp + '\\n' + 'def main(): \\n\\t'\nfinal_prompt = add_prompt + exp1 + exp + '\\n'\n# +  func + f'\"\"\"\\n{exp1}\\n\"\"\"'\nprint(final_prompt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer(final_prompt, return_tensors = 'pt').to('cuda')\ngeneration_config = GenerationConfig(max_new_tokens=150, temperature= 1.2, do_sample=True)\n\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens = 200,\n        generation_config=generation_config,\n        pad_token_id = tokenizer.pad_token_id,\n    )[0],\n    skip_special_tokens=True\n)\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{final_prompt}')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataset_formation(data):\n    add_prompt = '<SYSTEM_TASK:>\\nGiven the following code description, write Python code to implement the functionality described below\\n<END_TASK>\\n<USER_TASK:>\\nDescription:\\n'\n    exp = prompted_data_1['train']['text_prompt']\n    final_prompt = add_prompt + func + '\\t' f'\"\"\"{exp}\"\"\"'\n    code = prompted_data_1['train']['text_prompt']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"add_prompt = '<SYSTEM_TASK:>\\nGiven the following code description, write Python code to implement the functionality described below\\n<END_TASK>\\n<USER_TASK:>\\nDescription:\\n'\n\ntext_prompt = 'def VGG16_model_architecture()\\n\"\"\"\\nInitialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function\\n\"\"\"\\n\\bdef train_test_split():\\n\\t\"\"\"Split the data X, Y in to train and test data using sklearn\"\"\"\\n\\bdef model_predict():\\n\\t\"\"\"Make prediction using the deep learning model defined above in VGG16_model_architecture function\"\"\"\\n'\n\nfinal_prompt = add_prompt + text_prompt\nprint(final_prompt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install git+https://github.com/huggingface/datasets#egg=datasets","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:27:06.260970Z","iopub.execute_input":"2023-08-30T17:27:06.261349Z","iopub.status.idle":"2023-08-30T17:27:34.840939Z","shell.execute_reply.started":"2023-08-30T17:27:06.261298Z","shell.execute_reply":"2023-08-30T17:27:34.839656Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting datasets\n  Cloning https://github.com/huggingface/datasets to /tmp/pip-install-5q8y4mj7/datasets_44d6e0a3e76f4a9eadefbd640a3c9d52\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/datasets /tmp/pip-install-5q8y4mj7/datasets_44d6e0a3e76f4a9eadefbd640a3c9d52\n  Resolved https://github.com/huggingface/datasets to commit 029227a116c14720afca71b9b22e78eb2a1c09a6\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\nBuilding wheels for collected packages: datasets\n  Building wheel for datasets (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for datasets: filename=datasets-2.14.4.dev0-py3-none-any.whl size=493133 sha256=832f585e84a398cd6d0ff3ef842f201d1a67d0530341a1f491411f86b4fba1f9\n  Stored in directory: /tmp/pip-ephem-wheel-cache-tg1a4xxv/wheels/7f/ba/ce/8f6a52388a9966c7d9afa987113a763f7c105f568f369adbc6\nSuccessfully built datasets\nInstalling collected packages: datasets\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\nSuccessfully installed datasets-2.14.4.dev0\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\ndataset_2 = load_dataset(\"code_x_glue_ct_code_to_text\", \"python\", download_mode=\"force_redownload\")","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:27:34.844261Z","iopub.execute_input":"2023-08-30T17:27:34.844670Z","iopub.status.idle":"2023-08-30T17:32:44.500890Z","shell.execute_reply.started":"2023-08-30T17:27:34.844629Z","shell.execute_reply":"2023-08-30T17:32:44.499803Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"650a2e46a87f42c3b643b160eb9f19d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/17.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"595616abc8014c8985c280aeff57228b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/25.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1970e139181497a996805f52abb8212"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/2.35k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e3939ef000b4bfd82f4b6d2450a461c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.74k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"948904687477499a9a7af9ff1f522422"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7da22e13bee64da1a09203a600818b10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/941M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6087a466876246d2a76e312882b41a6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/12.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecef953730cc4ad0af5bb1ec80c03155"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89f1c1349f3f473eb7bc68eb72198f2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1407dcff10ed4f6c86d91b85d835bf86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/941M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f6ac859017e4dbb89d71b91eddd6adb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/12.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"facae8304937414aa3a3cf1c89bc104f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d729ed4d4ead4a4eb86c1a5d8225d83b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ece2e6f09e44416be6ce06a3c4c568c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/941M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c02368ae53fd457481bb789ead3718cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/12.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2772979c6d4f45bc914f2dbc24427034"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c306b913c0c4d84b4ee8fdf99b5db00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/251820 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"979710c83fd34823a43a44f7ad8d468b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/13914 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"272f670b5fce42a6abcecf694ebeac9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/14918 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edee2e6b58294a788d9fa9aacd23e670"}},"metadata":{}}]},{"cell_type":"code","source":"dataset_2","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:32:59.110923Z","iopub.execute_input":"2023-08-30T17:32:59.111284Z","iopub.status.idle":"2023-08-30T17:32:59.119668Z","shell.execute_reply.started":"2023-08-30T17:32:59.111249Z","shell.execute_reply":"2023-08-30T17:32:59.118488Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url'],\n        num_rows: 251820\n    })\n    validation: Dataset({\n        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url'],\n        num_rows: 13914\n    })\n    test: Dataset({\n        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url'],\n        num_rows: 14918\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(dataset_2['train'][5645]['code'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:33:01.990820Z","iopub.execute_input":"2023-08-30T17:33:01.991177Z","iopub.status.idle":"2023-08-30T17:33:01.997649Z","shell.execute_reply.started":"2023-08-30T17:33:01.991146Z","shell.execute_reply":"2023-08-30T17:33:01.996497Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"def check_table_formats(files):\n    \"\"\"\n    Determine whether a list of files are of a recognizable output type.\n\n    Parameters\n    ----------\n    files : str\n        A list of file names\n\n    Returns\n    -------\n    result : bool\n        True if *all* the file names are supported\n    \"\"\"\n    cont = True\n    formats = get_table_formats()\n    for t in files.split(','):\n        _, ext = os.path.splitext(t)\n        ext = ext[1:].lower()\n        if ext not in formats:\n            cont = False\n            log.warn(\"Format not supported for {0} ({1})\".format(t, ext))\n    if not cont:\n        log.error(\"Invalid table format specified.\")\n    return cont\n","output_type":"stream"}]},{"cell_type":"code","source":"print(dataset_2['train'][43]['docstring'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:33:05.250255Z","iopub.execute_input":"2023-08-30T17:33:05.251346Z","iopub.status.idle":"2023-08-30T17:33:05.257832Z","shell.execute_reply.started":"2023-08-30T17:33:05.251288Z","shell.execute_reply":"2023-08-30T17:33:05.256851Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Mark a callable as exclusive\n\n    :param via: factory for a Lock to guard the callable\n\n    Guards the callable against being entered again before completion.\n    Explicitly raises a :py:exc:`RuntimeError` on violation.\n\n    :note: If applied to a method, it is exclusive across all instances.\n","output_type":"stream"}]},{"cell_type":"code","source":"def dataset_formation(data):\n    doc = data['docstring'].split('\\n')\n#     for i in range()\n    add_prompt = f'<SYSTEM_TASK:>\\n{doc[0]}\\n<END_TASK>\\n<USER_TASK:>\\nDescription:\\n'\n    s = data['code']\n    final_prompt = ''\n    code = ''\n    occurrences = re.finditer('\"\"\"', s)\n    # using reduce() to get start indices of all occurrences\n    res = reduce(lambda x, y: x + [y.start()], occurrences, [])\n    if len(res) > 1:     \n        pos = res[1]\n        prompt = data['code'][:pos+3]\n        final_prompt = add_prompt +prompt\n        code = s.replace(prompt, '')\n    return{\n        'text_prompt' : final_prompt,\n        'code_prompt' : code\n    }","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:33:09.725442Z","iopub.execute_input":"2023-08-30T17:33:09.725799Z","iopub.status.idle":"2023-08-30T17:33:09.734407Z","shell.execute_reply.started":"2023-08-30T17:33:09.725762Z","shell.execute_reply":"2023-08-30T17:33:09.732315Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"prompted_dataset_2 = dataset_2.map(dataset_formation, batched = False, remove_columns = dataset_2['train'].column_names)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:36:15.485442Z","iopub.execute_input":"2023-08-30T17:36:15.486022Z","iopub.status.idle":"2023-08-30T17:36:50.477451Z","shell.execute_reply.started":"2023-08-30T17:36:15.485988Z","shell.execute_reply":"2023-08-30T17:36:50.476366Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/251820 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b1446df85cf41b88b9f989e7cede37e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13914 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05a77ded384b4e4fbd16ee7b8dc33464"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14918 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbbba365eb5242bba280a8af0dc458c4"}},"metadata":{}}]},{"cell_type":"code","source":"prompted_dataset_2","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:36:53.030558Z","iopub.execute_input":"2023-08-30T17:36:53.030942Z","iopub.status.idle":"2023-08-30T17:36:53.038907Z","shell.execute_reply.started":"2023-08-30T17:36:53.030910Z","shell.execute_reply":"2023-08-30T17:36:53.037797Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text_prompt', 'code_prompt'],\n        num_rows: 251820\n    })\n    validation: Dataset({\n        features: ['text_prompt', 'code_prompt'],\n        num_rows: 13914\n    })\n    test: Dataset({\n        features: ['text_prompt', 'code_prompt'],\n        num_rows: 14918\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(prompted_dataset_2['train'][343]['text_prompt'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:36:53.601496Z","iopub.execute_input":"2023-08-30T17:36:53.601989Z","iopub.status.idle":"2023-08-30T17:36:53.613306Z","shell.execute_reply.started":"2023-08-30T17:36:53.601944Z","shell.execute_reply":"2023-08-30T17:36:53.612392Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"<SYSTEM_TASK:>\nCheck if given regex is of type ECMA 262 or not.\n<END_TASK>\n<USER_TASK:>\nDescription:\ndef is_ecma_regex(regex):\n    \"\"\"Check if given regex is of type ECMA 262 or not.\n\n    :rtype: bool\n\n    \"\"\"\n","output_type":"stream"}]},{"cell_type":"code","source":"print(prompted_dataset_2['train'][343]['code_prompt'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:36:56.450206Z","iopub.execute_input":"2023-08-30T17:36:56.450896Z","iopub.status.idle":"2023-08-30T17:36:56.456530Z","shell.execute_reply.started":"2023-08-30T17:36:56.450861Z","shell.execute_reply":"2023-08-30T17:36:56.455554Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"\n    parts = regex.split('/')\n\n    if len(parts) == 1:\n        return False\n\n    if len(parts) < 3:\n        raise ValueError('Given regex isn\\'t ECMA regex nor Python regex.')\n    parts.pop()\n    parts.append('')\n\n    raw_regex = '/'.join(parts)\n    if raw_regex.startswith('/') and raw_regex.endswith('/'):\n        return True\n    return False\n","output_type":"stream"}]},{"cell_type":"code","source":"final_prompt = prompted_dataset_2['train'][374]['text_prompt']\ncode = prompted_dataset_2['train'][374]['code_prompt']\ninputs = tokenizer(final_prompt, return_tensors = 'pt').to('cuda')\ngeneration_config = GenerationConfig(max_new_tokens=150, temperature= 0.5, do_sample=True, top_p = 1)\n\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens = 200,\n        generation_config=generation_config,\n        pad_token_id = tokenizer.pad_token_id,\n    )[0],\n    skip_special_tokens=True\n)\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{final_prompt}')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output}')\nprint(dash_line)\nprint(f'BASELINE HUMAN WRITTEN CODE:\\n{code}')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:32:45.970434Z","iopub.status.idle":"2023-08-30T17:32:45.970890Z","shell.execute_reply.started":"2023-08-30T17:32:45.970651Z","shell.execute_reply":"2023-08-30T17:32:45.970673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The above dataset is working GOOD**","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\ndataset_3 = load_dataset(\"openai_humaneval\")","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:23.320519Z","iopub.execute_input":"2023-08-30T17:37:23.320889Z","iopub.status.idle":"2023-08-30T17:37:25.186261Z","shell.execute_reply.started":"2023-08-30T17:37:23.320857Z","shell.execute_reply":"2023-08-30T17:37:25.185349Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/3.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99c8a48b8d774577a9b3d08968b98318"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/3.33k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01539a7ae10c4b1db549ae383d66efa9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/6.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4db04f14ecaa4114bf87e98c9e051f8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/44.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d34bb1019364fd785d98cb8911f2fdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/164 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99aa8052bad14009b984f33e634dc7be"}},"metadata":{}}]},{"cell_type":"code","source":"dataset_3","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:25.188233Z","iopub.execute_input":"2023-08-30T17:37:25.189224Z","iopub.status.idle":"2023-08-30T17:37:25.195604Z","shell.execute_reply.started":"2023-08-30T17:37:25.189187Z","shell.execute_reply":"2023-08-30T17:37:25.194647Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    test: Dataset({\n        features: ['task_id', 'prompt', 'canonical_solution', 'test', 'entry_point'],\n        num_rows: 164\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(dataset_3['test'][50]['prompt'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:25.197385Z","iopub.execute_input":"2023-08-30T17:37:25.197726Z","iopub.status.idle":"2023-08-30T17:37:25.208837Z","shell.execute_reply.started":"2023-08-30T17:37:25.197693Z","shell.execute_reply":"2023-08-30T17:37:25.207745Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"\n\ndef encode_shift(s: str):\n    \"\"\"\n    returns encoded string by shifting every character by 5 in the alphabet.\n    \"\"\"\n    return \"\".join([chr(((ord(ch) + 5 - ord(\"a\")) % 26) + ord(\"a\")) for ch in s])\n\n\ndef decode_shift(s: str):\n    \"\"\"\n    takes as input string encoded with encode_shift function. Returns decoded string.\n    \"\"\"\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print(dataset_3['test'][10]['canonical_solution'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:26.460216Z","iopub.execute_input":"2023-08-30T17:37:26.460906Z","iopub.status.idle":"2023-08-30T17:37:26.466422Z","shell.execute_reply.started":"2023-08-30T17:37:26.460869Z","shell.execute_reply":"2023-08-30T17:37:26.465494Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"    if not string:\n        return ''\n\n    beginning_of_suffix = 0\n\n    while not is_palindrome(string[beginning_of_suffix:]):\n        beginning_of_suffix += 1\n\n    return string + string[:beginning_of_suffix][::-1]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"def dataset_formation(data):\n    add_prompt = '<SYSTEM_TASK:>\\nGiven the following code description, write Python code to implement the functionality described below\\n<END_TASK>\\n<USER_TASK:>\\nDescription:\\n'\n    prompt = data['prompt']\n    final_prompt = add_prompt + prompt\n    code = data['canonical_solution']\n    return{\n        'text_prompt' : final_prompt,\n        'code_prompt' : code\n    }","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:28.080542Z","iopub.execute_input":"2023-08-30T17:37:28.080927Z","iopub.status.idle":"2023-08-30T17:37:28.089079Z","shell.execute_reply.started":"2023-08-30T17:37:28.080895Z","shell.execute_reply":"2023-08-30T17:37:28.087986Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"prompted_dataset_3 = dataset_3.map(dataset_formation, batched = False, remove_columns = dataset_3['test'].column_names)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:28.630205Z","iopub.execute_input":"2023-08-30T17:37:28.630894Z","iopub.status.idle":"2023-08-30T17:37:28.679422Z","shell.execute_reply.started":"2023-08-30T17:37:28.630860Z","shell.execute_reply":"2023-08-30T17:37:28.677519Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/164 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cad3b83ed2da4c74814ab0950c7cf95f"}},"metadata":{}}]},{"cell_type":"code","source":"prompted_dataset_3","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:29.870709Z","iopub.execute_input":"2023-08-30T17:37:29.871102Z","iopub.status.idle":"2023-08-30T17:37:29.878288Z","shell.execute_reply.started":"2023-08-30T17:37:29.871071Z","shell.execute_reply":"2023-08-30T17:37:29.877293Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    test: Dataset({\n        features: ['text_prompt', 'code_prompt'],\n        num_rows: 164\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(prompted_dataset_3['test'][34]['text_prompt'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:30.350565Z","iopub.execute_input":"2023-08-30T17:37:30.350923Z","iopub.status.idle":"2023-08-30T17:37:30.356735Z","shell.execute_reply.started":"2023-08-30T17:37:30.350893Z","shell.execute_reply":"2023-08-30T17:37:30.355733Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"<SYSTEM_TASK:>\nGiven the following code description, write Python code to implement the functionality described below\n<END_TASK>\n<USER_TASK:>\nDescription:\n\n\ndef unique(l: list):\n    \"\"\"Return sorted unique elements in a list\n    >>> unique([5, 3, 5, 2, 3, 3, 9, 0, 123])\n    [0, 2, 3, 5, 9, 123]\n    \"\"\"\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print(prompted_dataset_3['test'][34]['code_prompt'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:30.358684Z","iopub.execute_input":"2023-08-30T17:37:30.359684Z","iopub.status.idle":"2023-08-30T17:37:30.371444Z","shell.execute_reply.started":"2023-08-30T17:37:30.359648Z","shell.execute_reply":"2023-08-30T17:37:30.370284Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"    return sorted(list(set(l)))\n\n","output_type":"stream"}]},{"cell_type":"code","source":"code = prompted_dataset_3['test'][5]['text_prompt']\nprint(code)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:32.040291Z","iopub.execute_input":"2023-08-30T17:37:32.040677Z","iopub.status.idle":"2023-08-30T17:37:32.046685Z","shell.execute_reply.started":"2023-08-30T17:37:32.040648Z","shell.execute_reply":"2023-08-30T17:37:32.045703Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"<SYSTEM_TASK:>\nGiven the following code description, write Python code to implement the functionality described below\n<END_TASK>\n<USER_TASK:>\nDescription:\nfrom typing import List\n\n\ndef intersperse(numbers: List[int], delimeter: int) -> List[int]:\n    \"\"\" Insert a number 'delimeter' between every two consecutive elements of input list `numbers'\n    >>> intersperse([], 4)\n    []\n    >>> intersperse([1, 2, 3], 4)\n    [1, 4, 2, 4, 3]\n    \"\"\"\n\n","output_type":"stream"}]},{"cell_type":"code","source":"final_prompt = prompted_dataset_3['test'][74]['text_prompt']\ncode = prompted_dataset_3['test'][74]['code_prompt']\ninputs = tokenizer(final_prompt, return_tensors = 'pt').to('cuda')\ngeneration_config = GenerationConfig(max_new_tokens=150, temperature= 0.1, do_sample=True, top_p = 4)\n\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens = 100,\n        generation_config=generation_config,\n        pad_token_id = tokenizer.pad_token_id,\n    )[0],\n    skip_special_tokens=True\n)\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{final_prompt}')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output}')\nprint(dash_line)\nprint(f'BASELINE HUMAN WRITTEN CODE:\\n{code}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Working Good**","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\ndataset_4 = load_dataset(\"codeparrot/github-jupyter-code-to-text\")","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:37.010379Z","iopub.execute_input":"2023-08-30T17:37:37.010745Z","iopub.status.idle":"2023-08-30T17:37:52.376645Z","shell.execute_reply.started":"2023-08-30T17:37:37.010714Z","shell.execute_reply":"2023-08-30T17:37:52.375706Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/857 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fc8a153efe14a0eae3ce59643092dfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c5af7d9491942d1a0d4af7011db0145"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/227M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e5a36330116482b9051343bcc83e577"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/56.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e500ab393ad84d91b60de5179aacd154"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a36df4674004c8f9ce5aa9f05022c1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a5e1b536f0f446f86f50773113b395b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f2f8b1ff3f74825ba0bc94dac473616"}},"metadata":{}}]},{"cell_type":"code","source":"dataset_4","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:52.378489Z","iopub.execute_input":"2023-08-30T17:37:52.378941Z","iopub.status.idle":"2023-08-30T17:37:52.385306Z","shell.execute_reply.started":"2023-08-30T17:37:52.378905Z","shell.execute_reply":"2023-08-30T17:37:52.384359Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['repo_name', 'path', 'license', 'content'],\n        num_rows: 47452\n    })\n    test: Dataset({\n        features: ['repo_name', 'path', 'license', 'content'],\n        num_rows: 11864\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(dataset_4['train'][23]['path'])    # useful\nprint(dataset_4['train'][23]['repo_name'])\nprint(dataset_4['train'][23]['license'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:52.386796Z","iopub.execute_input":"2023-08-30T17:37:52.387471Z","iopub.status.idle":"2023-08-30T17:37:53.240415Z","shell.execute_reply.started":"2023-08-30T17:37:52.387435Z","shell.execute_reply":"2023-08-30T17:37:53.239405Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"lucid_work/notebooks/feature_visualization.ipynb\ndavidparks21/qso_lya_detection_pipeline\nmit\n","output_type":"stream"}]},{"cell_type":"code","source":"print(dataset_4['train'][263]['content'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:53.244112Z","iopub.execute_input":"2023-08-30T17:37:53.244924Z","iopub.status.idle":"2023-08-30T17:37:53.326352Z","shell.execute_reply.started":"2023-08-30T17:37:53.244879Z","shell.execute_reply":"2023-08-30T17:37:53.325345Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"%run ../bst/bst.py\n%load ../bst/bst.py\n\ndef height(node):\n    # TODO: Implement me\n    pass\n\n\"\"\"\nExplanation: <small><i>This notebook was prepared by Donne Martin. Source and license info is on GitHub.</i></small>\nChallenge Notebook\nProblem: Determine the height of a tree.\n\nConstraints\nTest Cases\nAlgorithm\nCode\nUnit Test\nSolution Notebook\n\nConstraints\n\nIs this a binary tree?\nYes\n\n\nCan we assume we already have a Node class with an insert method?\nYes\n\n\n\nTest Cases\n\n5 -> 1\n5, 2, 8, 1, 3 -> 3\n\nAlgorithm\nRefer to the Solution Notebook.  If you are stuck and need a hint, the solution notebook's algorithm discussion might be a good place to start.\nCode\nEnd of explanation\n\"\"\"\n\n\n# %load test_height.py\nfrom nose.tools import assert_equal\n\n\nclass TestHeight(object):\n\n    def test_height(self):\n        root = Node(5)\n        assert_equal(height(root), 1)\n        insert(root, 2)\n        insert(root, 8)\n        insert(root, 1)\n        insert(root, 3)\n        assert_equal(height(root), 3)\n\n        print('Success: test_height')\n\n\ndef main():\n    test = TestHeight()\n    test.test_height()\n\n\nif __name__ == '__main__':\n    main()\n\n\"\"\"\nExplanation: Unit Test\nThe following unit test is expected to fail until you solve the challenge.\nEnd of explanation\n\"\"\"\n\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import fasttext\nfrom huggingface_hub import hf_hub_download\n\nmodel_path = hf_hub_download(repo_id=\"facebook/fasttext-language-identification\", filename=\"model.bin\")\ndetect = fasttext.load_model(model_path)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:53.327782Z","iopub.execute_input":"2023-08-30T17:37:53.328735Z","iopub.status.idle":"2023-08-30T17:37:59.622316Z","shell.execute_reply.started":"2023-08-30T17:37:53.328698Z","shell.execute_reply":"2023-08-30T17:37:59.621178Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.bin:   0%|          | 0.00/1.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfb039cad3f54f829a26fa428f979dce"}},"metadata":{}},{"name":"stderr","text":"Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n","output_type":"stream"}]},{"cell_type":"code","source":"def detect_lang(data):\n    lines = data.split('\\n')\n    text = ''\n    for i in range(len(lines)):\n        if i < 4:\n            text = text + lines[i]\n        else:\n            break\n    lang = detect.predict(text)[0][0]\n    if lang == '__label__eng_Latn':\n        return 'en'\n    else:\n        return ''","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:59.624171Z","iopub.execute_input":"2023-08-30T17:37:59.625405Z","iopub.status.idle":"2023-08-30T17:37:59.631859Z","shell.execute_reply.started":"2023-08-30T17:37:59.625365Z","shell.execute_reply":"2023-08-30T17:37:59.630964Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def dataset_formation(data):\n    add_prompt = '<SYSTEM_TASK:>\\nGiven the following code description, write Python code to implement the functionality described below\\n<END_TASK>\\n<USER_TASK:>\\nDescription:\\n'\n    s = data['content']\n    dummy = data['content']\n    occurrences = re.finditer('\"\"\"', s)\n    # using reduce() to get start indices of all occurrences\n    res = reduce(lambda x, y: x + [y.start()], occurrences, [])\n    extracted_prompt_arr = []\n    extracted_code = ''\n    final_prompt = ''\n    code = ''\n    if len(res)%2 == 0:\n        for i in range(int(len(res)/2)):\n            extracted_prompt_arr.append(s[res[2*i] + 3 : res[2*i + 1]] + '\\n')\n            dummy = dummy.replace(s[res[2*i] : res[2*i + 1] + 3], '')\n        final = ''\n        extracted_code = dummy\n        # LANGUAGE DETECTION  \n        lang = detect_lang(extracted_prompt_arr[0])\n        if lang == 'en':\n            final_1, final_2 = '', ''\n            for i in range(len(extracted_prompt_arr)):\n                    exp = extracted_prompt_arr[i]\n                    occurrences_1 = re.finditer('Explanation:', exp)\n                    # using reduce() to get start indices of all occurrences\n                    start = reduce(lambda x, y: x + [y.start()], occurrences_1, [])\n                    occurrences_2 = re.finditer('End of explanation', exp)\n                    end = reduce(lambda x, y: x + [y.start()], occurrences_2, [])\n                    if len(start) != 0 and len(end) != 0:\n                        extracted_exp = exp[start[0] + 12 : end[0]]\n                        final_1 = final_1 + extracted_exp + '\\n'\n            final_2 = final_1\n            occurrences_3 = re.finditer('<', final_1)\n            start = reduce(lambda x, y: x + [y.start()], occurrences_3, [])   \n            occurrences_4 = re.finditer('>', final_1)\n            end = reduce(lambda x, y: x + [y.start()], occurrences_4, [])\n            if len(start) == len(end) and len(start) != 0:\n                for i in range(len(start)):\n                    final_2 = final_2.replace(final_1[start[i] : end[i]], '')\n            else:\n                final_2 = final_1\n            final_3 = final_2\n            occurrences_5 = re.finditer('<', final_2)\n            start = reduce(lambda x, y: x + [y.start()], occurrences_5, [])   \n            occurrences_6 = re.finditer('>', final_2)\n            end = reduce(lambda x, y: x + [y.start()], occurrences_6, [])\n            if len(start) == len(end) and len(start) != 0:\n                for i in range(len(start)):\n                    final_3 = final_3.replace(final_2[start[i] : end[i]], '')\n            else:\n                final_3 = final_2\n            final = final_3 \n            if final != '':\n                final_line = ''\n                arr = final.split('\\n')\n                for i in range(len(arr)):\n                    if i < 9:\n                        final_line = final_line + arr[i] + ' '\n                path = data['path'].split('/')\n                func = path[-1].split('.')\n                final_prompt = add_prompt + f'def {func[0]}():' + '\\n\\t' + f'\"\"\"{final_line}\"\"\"'   \n                lines = extracted_code.split('\\n')\n                code = ''\n                if len(lines) > 1:\n                    for i in range(len(lines)):\n                        if len(lines[i]) != 0:\n                            if lines[i][0] != '#':\n                                code = code + lines[i] + '\\n'\n                            else:\n                                pass\n                else:\n                    code = extracted_code\n    else:\n        print('Error ^_^')\n            \n    return{\n        'text_prompt' : final_prompt,\n        'code_prompt' : code\n    }   ","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:37:59.634382Z","iopub.execute_input":"2023-08-30T17:37:59.635058Z","iopub.status.idle":"2023-08-30T17:38:01.089515Z","shell.execute_reply.started":"2023-08-30T17:37:59.635024Z","shell.execute_reply":"2023-08-30T17:38:01.088348Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"prompted_dataset_4 = dataset_4.map(dataset_formation, batched = False, remove_columns = dataset_4['train'].column_names)\n\nprompted_dataset_4","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:38:01.090949Z","iopub.execute_input":"2023-08-30T17:38:01.091510Z","iopub.status.idle":"2023-08-30T17:39:00.461954Z","shell.execute_reply.started":"2023-08-30T17:38:01.091476Z","shell.execute_reply":"2023-08-30T17:39:00.461004Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"Parameter 'function'=<function dataset_formation at 0x7fceff46b1c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/47452 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bab83c3f24b4128bfdb7ade00ac0dda"}},"metadata":{}},{"name":"stdout","text":"Error ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11864 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69c3681131744f66ae0c679b35741ccc"}},"metadata":{}},{"name":"stdout","text":"Error ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\nError ^_^\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text_prompt', 'code_prompt'],\n        num_rows: 47452\n    })\n    test: Dataset({\n        features: ['text_prompt', 'code_prompt'],\n        num_rows: 11864\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(prompted_dataset_4['train'][14964]['text_prompt'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:39:00.463312Z","iopub.execute_input":"2023-08-30T17:39:00.463755Z","iopub.status.idle":"2023-08-30T17:39:00.470241Z","shell.execute_reply.started":"2023-08-30T17:39:00.463719Z","shell.execute_reply":"2023-08-30T17:39:00.469312Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"<SYSTEM_TASK:>\nGiven the following code description, write Python code to implement the functionality described below\n<END_TASK>\n<USER_TASK:>\nDescription:\ndef student_intervention-checkpoint():\n\t\"\"\" Project 2: Supervised Learning Building a Student Intervention System 1. Classification vs Regression Your goal is to identify students who might need early intervention - which type of supervised machine learning problem is this, classification or regression? Why? It is a classification problem. Because the output contains just 2 classes i.e. pass: yes or no.  2. Exploring the Data Let's go ahead and read in the student dataset first. To execute a code cell, click inside it and press Shift+Enter.  \"\"\"\n","output_type":"stream"}]},{"cell_type":"code","source":"print(prompted_dataset_4['train'][6]['code_prompt'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T17:39:00.473663Z","iopub.execute_input":"2023-08-30T17:39:00.474317Z","iopub.status.idle":"2023-08-30T17:39:00.589530Z","shell.execute_reply.started":"2023-08-30T17:39:00.474284Z","shell.execute_reply":"2023-08-30T17:39:00.588527Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport yaml\nwith open(\"data/swiss-reviews.txt\", 'r') as fp:\n    swiss_rev = fp.readlines()\nlen(swiss_rev)\nswiss_rev[2]\ndef filter_helpful(line):\n    l = line.rstrip('\\n')\n    l = yaml.load(l)\n    if('helpful' in l.keys()):\n        if(l['helpful'][1] >= 5):\n            return True\n        else:\n            return False\n    else:\n        print(\"Review does not have helpful score key: \"+line)\n        return False\ndef get_helpful(data):\n    res = []\n    counter = 1\n    i = 0\n    for line in data:\n        i += 1\n        if(filter_helpful(line)):\n            if(counter % 1000 == 0):\n                print(\"Count \"+str(counter)+\" / \"+str(i))\n            counter += 1\n            res.append(line)\n    return res\nswiss_reviews_helpful = get_helpful(swiss_rev)\nlen(swiss_reviews_helpful)\nwrite_file = open('data/swiss-reviews-helpful-correct-bigger.txt', 'w')\nfor item in swiss_reviews_helpful:\n  write_file.write(item)\nwrite_file.close()\nwith open('data/swiss-reviews-helpful-correct-bigger.txt', 'r') as fp:\n    swiss_reviews_helpful = fp.readlines()\ndef filter_asin(line):\n    l = line.rstrip('\\n')\n    l = yaml.load(l)\n    if('asin' in l.keys()):\n        return l['asin']\n    else:\n        return ''\nhelpful_asins = []\ncounter = 1\nfor item in swiss_reviews_helpful:\n    if(counter%500 == 0):\n        print(counter)\n    counter += 1\n    x = filter_asin(item)\n    if(len(x) > 0):\n        helpful_asins.append(x)\nimport pickle\nwith open('data/helpful_asins_bigger.pickle', 'wb') as fp:\n    pickle.dump(helpful_asins, fp)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"final_prompt = prompted_dataset_4['test'][7114]['text_prompt']\ncode = prompted_dataset_4['test'][7114]['code_prompt']\ninputs = tokenizer(final_prompt, return_tensors = 'pt').to('cuda')\ngeneration_config = GenerationConfig(max_new_tokens=150, temperature= 1.5, do_sample=True, top_k = 5)\n\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens = 150,\n        generation_config=generation_config,\n        pad_token_id = tokenizer.pad_token_id,\n    )[0],\n    skip_special_tokens=True\n)\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{final_prompt}')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output}')\nprint(dash_line)\nprint(f'BASELINE HUMAN WRITTEN CODE:\\n{code}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This dataset is OKAYISH so we will take 35% of this dataset","metadata":{}},{"cell_type":"markdown","source":"**Preparing final dataset**","metadata":{}},{"cell_type":"code","source":"# converting dataset_2 to pandas dataframe\nimport pandas as pd\ndf_1 = prompted_dataset_3['test'].to_pandas()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:28:39.070124Z","iopub.execute_input":"2023-08-30T19:28:39.070510Z","iopub.status.idle":"2023-08-30T19:28:39.077856Z","shell.execute_reply.started":"2023-08-30T19:28:39.070478Z","shell.execute_reply":"2023-08-30T19:28:39.076860Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"df_2 = prompted_dataset_2['train'].to_pandas()\ndf_3 = prompted_dataset_2['test'].to_pandas()\ndf_4 = prompted_dataset_2['validation'].to_pandas()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:28:40.250029Z","iopub.execute_input":"2023-08-30T19:28:40.250753Z","iopub.status.idle":"2023-08-30T19:28:40.577513Z","shell.execute_reply.started":"2023-08-30T19:28:40.250709Z","shell.execute_reply":"2023-08-30T19:28:40.576463Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"df_5 = prompted_dataset_4['train'].to_pandas()\ndf_6 = prompted_dataset_4['test'].to_pandas()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:28:40.889838Z","iopub.execute_input":"2023-08-30T19:28:40.890194Z","iopub.status.idle":"2023-08-30T19:28:41.131214Z","shell.execute_reply.started":"2023-08-30T19:28:40.890156Z","shell.execute_reply":"2023-08-30T19:28:41.130218Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"l = int(len(df_5)*0.25)\ndf_5 = df_5[:l]\ndf_6 = df_6[:l]","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:28:41.560100Z","iopub.execute_input":"2023-08-30T19:28:41.561033Z","iopub.status.idle":"2023-08-30T19:28:41.566317Z","shell.execute_reply.started":"2023-08-30T19:28:41.560989Z","shell.execute_reply":"2023-08-30T19:28:41.565056Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"frames = [df_1, df_2,df_3, df_4, df_5, df_6]\n\ndf_final = pd.concat(frames, axis = 0, join = 'outer')\ndf_final.reset_index(inplace = True)\ndf_final.drop(['index'], axis = 1, inplace = True)\nprint(len(df_final))\ndf_final.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:28:42.229995Z","iopub.execute_input":"2023-08-30T19:28:42.230378Z","iopub.status.idle":"2023-08-30T19:28:42.279063Z","shell.execute_reply.started":"2023-08-30T19:28:42.230340Z","shell.execute_reply":"2023-08-30T19:28:42.277863Z"},"trusted":true},"execution_count":199,"outputs":[{"name":"stdout","text":"304542\n","output_type":"stream"},{"execution_count":199,"output_type":"execute_result","data":{"text/plain":"                                         text_prompt  \\\n0  <SYSTEM_TASK:>\\nGiven the following code descr...   \n1  <SYSTEM_TASK:>\\nGiven the following code descr...   \n2  <SYSTEM_TASK:>\\nGiven the following code descr...   \n3  <SYSTEM_TASK:>\\nGiven the following code descr...   \n4  <SYSTEM_TASK:>\\nGiven the following code descr...   \n\n                                         code_prompt  \n0      for idx, elem in enumerate(numbers):\\n    ...  \n1      result = []\\n    current_string = []\\n    ...  \n2                              return number % 1.0\\n  \n3      balance = 0\\n\\n    for op in operations:\\n...  \n4      mean = sum(numbers) / len(numbers)\\n    re...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_prompt</th>\n      <th>code_prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;SYSTEM_TASK:&gt;\\nGiven the following code descr...</td>\n      <td>for idx, elem in enumerate(numbers):\\n    ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;SYSTEM_TASK:&gt;\\nGiven the following code descr...</td>\n      <td>result = []\\n    current_string = []\\n    ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;SYSTEM_TASK:&gt;\\nGiven the following code descr...</td>\n      <td>return number % 1.0\\n</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;SYSTEM_TASK:&gt;\\nGiven the following code descr...</td>\n      <td>balance = 0\\n\\n    for op in operations:\\n...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;SYSTEM_TASK:&gt;\\nGiven the following code descr...</td>\n      <td>mean = sum(numbers) / len(numbers)\\n    re...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_final.drop_duplicates(inplace = True)\ndf_final.dropna(inplace = True)\ndf_final.sample(frac = 1)\ndf_final.reset_index(inplace = True)\ndf_final.drop(['index'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:28:44.162884Z","iopub.execute_input":"2023-08-30T19:28:44.163243Z","iopub.status.idle":"2023-08-30T19:28:45.307742Z","shell.execute_reply.started":"2023-08-30T19:28:44.163213Z","shell.execute_reply":"2023-08-30T19:28:45.306808Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"def detect_lang(data):\n    lang = detect.predict(data)[0][0]\n    if lang == '__label__eng_Latn':\n        return 'en'\n    else:\n        return ''\n    \n    \nfor i in range(len(df_final)):\n    prompt = df_final['text_prompt'][i]\n    prompt = prompt.replace('\\n', '')\n    prompt = prompt[:2000]\n    lang = detect_lang(prompt)\n    if lang != 'en':\n        df_final.drop([i], axis = 0, inplace = True)\n    else:\n        pass","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:28:45.548381Z","iopub.execute_input":"2023-08-30T19:28:45.549260Z","iopub.status.idle":"2023-08-30T19:47:47.892357Z","shell.execute_reply.started":"2023-08-30T19:28:45.549214Z","shell.execute_reply":"2023-08-30T19:47:47.891350Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"print(len(df_final))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:48:19.900939Z","iopub.execute_input":"2023-08-30T19:48:19.901341Z","iopub.status.idle":"2023-08-30T19:48:19.908274Z","shell.execute_reply.started":"2023-08-30T19:48:19.901293Z","shell.execute_reply":"2023-08-30T19:48:19.907232Z"},"trusted":true},"execution_count":207,"outputs":[{"name":"stdout","text":"233208\n","output_type":"stream"}]},{"cell_type":"code","source":"split = 0.6\ntrain_df = df_final[:int(len(df_final)*split)]\ntest_df = df_final[int(len(df_final)*0.6): int(len(df_final)*0.8)]\nval_df = df_final[int(len(df_final)*0.8):]\n\nprint(len(val_df), len(df_final), len(test_df))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:48:53.372717Z","iopub.execute_input":"2023-08-30T19:48:53.373084Z","iopub.status.idle":"2023-08-30T19:48:53.384022Z","shell.execute_reply.started":"2023-08-30T19:48:53.373053Z","shell.execute_reply":"2023-08-30T19:48:53.379546Z"},"trusted":true},"execution_count":209,"outputs":[{"name":"stdout","text":"46642 233208 46642\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df.reset_index(inplace = True)\ntest_df.reset_index(inplace = True)\nval_df.reset_index(inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:49:02.250778Z","iopub.execute_input":"2023-08-30T19:49:02.251157Z","iopub.status.idle":"2023-08-30T19:49:02.260269Z","shell.execute_reply.started":"2023-08-30T19:49:02.251127Z","shell.execute_reply":"2023-08-30T19:49:02.259006Z"},"trusted":true},"execution_count":210,"outputs":[]},{"cell_type":"code","source":"train_df.drop(['index'], axis = 1, inplace = True)\ntest_df.drop(['index'], axis = 1, inplace = True)\nval_df.drop(['index'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:49:04.668088Z","iopub.execute_input":"2023-08-30T19:49:04.669214Z","iopub.status.idle":"2023-08-30T19:49:04.693191Z","shell.execute_reply.started":"2023-08-30T19:49:04.669172Z","shell.execute_reply":"2023-08-30T19:49:04.692209Z"},"trusted":true},"execution_count":211,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_28/3316440186.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df.drop(['index'], axis = 1, inplace = True)\n/tmp/ipykernel_28/3316440186.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  test_df.drop(['index'], axis = 1, inplace = True)\n/tmp/ipykernel_28/3316440186.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  val_df.drop(['index'], axis = 1, inplace = True)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(None in train_df, None in test_df, None in val_df)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:49:07.110177Z","iopub.execute_input":"2023-08-30T19:49:07.111631Z","iopub.status.idle":"2023-08-30T19:49:07.118596Z","shell.execute_reply.started":"2023-08-30T19:49:07.111584Z","shell.execute_reply":"2023-08-30T19:49:07.117645Z"},"trusted":true},"execution_count":212,"outputs":[{"name":"stdout","text":"False False False\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df.to_csv('train_data.csv', index = False, index_label=None)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:51:17.100742Z","iopub.execute_input":"2023-08-30T19:51:17.101451Z","iopub.status.idle":"2023-08-30T19:51:23.579008Z","shell.execute_reply.started":"2023-08-30T19:51:17.101414Z","shell.execute_reply":"2023-08-30T19:51:23.577977Z"},"trusted":true},"execution_count":220,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv('test_data.csv', index = False, index_label=None)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:55:20.261503Z","iopub.execute_input":"2023-08-30T19:55:20.261896Z","iopub.status.idle":"2023-08-30T19:55:22.392778Z","shell.execute_reply.started":"2023-08-30T19:55:20.261867Z","shell.execute_reply":"2023-08-30T19:55:22.391679Z"},"trusted":true},"execution_count":221,"outputs":[]},{"cell_type":"code","source":"val_df.to_csv('validation_data.csv', index = False, index_label=None)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T19:55:22.394867Z","iopub.execute_input":"2023-08-30T19:55:22.395254Z","iopub.status.idle":"2023-08-30T19:55:27.490483Z","shell.execute_reply.started":"2023-08-30T19:55:22.395219Z","shell.execute_reply":"2023-08-30T19:55:27.489461Z"},"trusted":true},"execution_count":222,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}