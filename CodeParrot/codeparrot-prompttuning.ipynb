{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U bitsandbytes\n!pip install -q -U git+https://github.com/huggingface/transformers.git\n!pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install -q -U git+https://github.com/huggingface/accelerate.git\n! pip install datasets\n! pip install torch","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:45:08.564102Z","iopub.execute_input":"2023-09-02T10:45:08.564478Z","iopub.status.idle":"2023-09-02T10:47:23.399365Z","shell.execute_reply.started":"2023-09-02T10:45:08.564447Z","shell.execute_reply":"2023-09-02T10:47:23.398157Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# special tokens for prompting\nsystem_token = \"<SYSTEM_TASK:>\"\nuser_token = \"<USER_TASK:>\"\nassistant_token = \"<ASSISTANT_TASK:>\"\nend_token = \"<END_TASK>\"\n\n\nmodel_checkpoint = 'codeparrot/codeparrot-small'\n# model_checkpoint = \"codeparrot/codeparrot\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint,\n                                          additional_special_tokens = [\"<SYSTEM_TASK:>\", \"<USER_TASK:>\", \"<ASSISTANT_TASK:>\", \"<END_TASK>\"],\n                                          pad_token = \"<PAD>\",\n                                          )","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:47:23.401995Z","iopub.execute_input":"2023-09-02T10:47:23.402383Z","iopub.status.idle":"2023-09-02T10:47:26.350456Z","shell.execute_reply.started":"2023-09-02T10:47:23.402343Z","shell.execute_reply":"2023-09-02T10:47:26.349329Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ba523230693412b8edc9a57421e2cbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/497k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"504448491aa347e597e9eea5a37f8ec4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/277k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15e9345051fb4668baaf5e5496b7d7b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/840k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ba0a9e5139347e29fa8aad2b4d98a70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e58ba38922a44460a60750c413cbc321"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:47:26.352012Z","iopub.execute_input":"2023-09-02T10:47:26.352638Z","iopub.status.idle":"2023-09-02T10:47:26.359764Z","shell.execute_reply.started":"2023-09-02T10:47:26.352600Z","shell.execute_reply":"2023-09-02T10:47:26.358710Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"GPT2TokenizerFast(name_or_path='codeparrot/codeparrot-small', vocab_size=32768, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<SYSTEM_TASK:>', '<USER_TASK:>', '<ASSISTANT_TASK:>', '<END_TASK>']}, clean_up_tokenization_spaces=True)"},"metadata":{}}]},{"cell_type":"code","source":"special_token_dict = tokenizer.special_tokens_map\nprint(special_token_dict)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:47:26.362694Z","iopub.execute_input":"2023-09-02T10:47:26.363354Z","iopub.status.idle":"2023-09-02T10:47:26.375287Z","shell.execute_reply.started":"2023-09-02T10:47:26.363319Z","shell.execute_reply":"2023-09-02T10:47:26.374337Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<SYSTEM_TASK:>', '<USER_TASK:>', '<ASSISTANT_TASK:>', '<END_TASK>']}\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.add_special_tokens(special_token_dict)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:47:26.376870Z","iopub.execute_input":"2023-09-02T10:47:26.377550Z","iopub.status.idle":"2023-09-02T10:47:26.390080Z","shell.execute_reply.started":"2023-09-02T10:47:26.377499Z","shell.execute_reply":"2023-09-02T10:47:26.388574Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"context_length = 10000","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:47:26.391850Z","iopub.execute_input":"2023-09-02T10:47:26.392794Z","iopub.status.idle":"2023-09-02T10:47:26.400021Z","shell.execute_reply.started":"2023-09-02T10:47:26.392760Z","shell.execute_reply":"2023-09-02T10:47:26.399039Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom transformers import BitsAndBytesConfig, AutoConfig, AutoModelForCausalLM, AutoModelWithLMHead\nimport torch\nfrom accelerate import init_empty_weights, infer_auto_device_map","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:47:26.401576Z","iopub.execute_input":"2023-09-02T10:47:26.402227Z","iopub.status.idle":"2023-09-02T10:47:38.104253Z","shell.execute_reply.started":"2023-09-02T10:47:26.402192Z","shell.execute_reply":"2023-09-02T10:47:38.103328Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(model_checkpoint,\n                                    vocab_size=tokenizer.vocab_size,\n                                    bos_token_id=tokenizer.bos_token_id,\n                                    eos_token_id=tokenizer.eos_token_id,\n)\n\nwith init_empty_weights():\n    model = AutoModelForCausalLM.from_config(config)\n    \nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:47:38.105457Z","iopub.execute_input":"2023-09-02T10:47:38.105786Z","iopub.status.idle":"2023-09-02T10:47:38.994480Z","shell.execute_reply.started":"2023-09-02T10:47:38.105752Z","shell.execute_reply":"2023-09-02T10:47:38.993465Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/903 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6753ef3a0a9f40e5a972157191bfd47c"}},"metadata":{}},{"name":"stdout","text":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(32768, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=32768, bias=False)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"device_map = infer_auto_device_map(model, no_split_module_classes = ['GPT2Block'])\nprint(device_map)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:47:38.996350Z","iopub.execute_input":"2023-09-02T10:47:38.996989Z","iopub.status.idle":"2023-09-02T10:47:46.794087Z","shell.execute_reply.started":"2023-09-02T10:47:38.996925Z","shell.execute_reply":"2023-09-02T10:47:46.793079Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"{'': 0}\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch \n\nnf4_config = BitsAndBytesConfig(\n   load_in_2bit=True,\n   bnb_4bit_quant_type=\"nf4\",\n   bnb_4bit_use_double_quant=True,\n   bnb_4bit_compute_dtype=torch.bfloat16\n)\n\n\n# model_id = \"codeparrot/codeparrot\"\nmodel_id = 'codeparrot/codeparrot-small'\nmodel =AutoModelForCausalLM.from_pretrained(model_id,\n                                            config = config,\n                                            device_map=\"auto\",\n                                            quantization_config=nf4_config,\n                                            torch_dtype=torch.bfloat16)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:47:46.797607Z","iopub.execute_input":"2023-09-02T10:47:46.798500Z","iopub.status.idle":"2023-09-02T10:47:50.567865Z","shell.execute_reply.started":"2023-09-02T10:47:46.798463Z","shell.execute_reply":"2023-09-02T10:47:50.566705Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/457M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8741f79fc55466bb79db71b648b988d"}},"metadata":{}}]},{"cell_type":"code","source":"model.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:47:50.569301Z","iopub.execute_input":"2023-09-02T10:47:50.569756Z","iopub.status.idle":"2023-09-02T10:47:50.590231Z","shell.execute_reply.started":"2023-09-02T10:47:50.569715Z","shell.execute_reply":"2023-09-02T10:47:50.589239Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32773. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Embedding(32773, 768)"},"metadata":{}}]},{"cell_type":"code","source":"def print_number_of_trainable_model_parameters(model):\n    trainable_model_params = 0\n    all_model_params = 0\n    for _, param in model.named_parameters():\n        all_model_params += param.numel()\n        if param.requires_grad:\n            trainable_model_params += param.numel()\n    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n\nprint(print_number_of_trainable_model_parameters(model))","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:47:50.591757Z","iopub.execute_input":"2023-09-02T10:47:50.592309Z","iopub.status.idle":"2023-09-02T10:47:50.608576Z","shell.execute_reply.started":"2023-09-02T10:47:50.592260Z","shell.execute_reply":"2023-09-02T10:47:50.607648Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"trainable model parameters: 111012096\nall model parameters: 111012096\npercentage of trainable model parameters: 100.00%\n","output_type":"stream"}]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:47:50.610011Z","iopub.execute_input":"2023-09-02T10:47:50.610366Z","iopub.status.idle":"2023-09-02T10:47:50.620966Z","shell.execute_reply.started":"2023-09-02T10:47:50.610334Z","shell.execute_reply":"2023-09-02T10:47:50.619938Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(32773, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=32773, bias=False)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"text_prompt = 'def return_files_size(filename):'\ncode =     'return os.path.getsize(filepath)'\n\ninputs = tokenizer(text_prompt, return_tensors = 'pt')\n\noutput = model.generate(**inputs,\n                       max_new_tokens = 50)\n\noutput = tokenizer.batch_decode(output,\n                          skip_special_tokens=True\n)\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{text_prompt}')\nprint(dash_line)\nprint(f'BASELINE HUMAN PYTHON CODE:\\n{code}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output[0]}')","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:47:50.622223Z","iopub.execute_input":"2023-09-02T10:47:50.622830Z","iopub.status.idle":"2023-09-02T10:48:04.924553Z","shell.execute_reply.started":"2023-09-02T10:47:50.622796Z","shell.execute_reply":"2023-09-02T10:48:04.923583Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1535: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\ndef return_files_size(filename):\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN PYTHON CODE:\nreturn os.path.getsize(filepath)\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\ndef return_files_size(filename):\n    \"\"\"\n    Return the size of the file in bytes.\n    \"\"\"\n    return os.path.getsize(filename)\n\n\ndef return_file_size(filename):\n    \"\"\"\n    Return the size of the file in bytes.\n    \"\"\"\n   \n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import GenerationConfig\n# generation_config = GenerationConfig(max_new_tokens=100, temperature=0.1)\n\ntext_prompt = 'def return_files_size(filename):'\ncode =     'return os.path.getsize(filepath)'\n\ninputs = tokenizer(text_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens = 100,\n#         generation_config=generation_config,\n        pad_token_id = tokenizer.pad_token_id,\n    )[0],\n    skip_special_tokens=True\n)\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{text_prompt}')\nprint(dash_line)\nprint(f'BASELINE HUMAN PYTHON CODE:\\n{code}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output}')","metadata":{"execution":{"iopub.status.busy":"2023-09-02T10:48:04.925890Z","iopub.execute_input":"2023-09-02T10:48:04.927576Z","iopub.status.idle":"2023-09-02T10:48:27.243812Z","shell.execute_reply.started":"2023-09-02T10:48:04.927537Z","shell.execute_reply":"2023-09-02T10:48:27.242610Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\ndef return_files_size(filename):\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN PYTHON CODE:\nreturn os.path.getsize(filepath)\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\ndef return_files_size(filename):\n    \"\"\"\n    Return the size of the file in bytes.\n    \"\"\"\n    return os.path.getsize(filename)\n\n\ndef return_file_size(filename):\n    \"\"\"\n    Return the size of the file in bytes.\n    \"\"\"\n    return os.path.getsize(filename)\n\n\ndef return_file_size_in_bytes(filename):\n    \"\"\"\n    Return the size of the file in bytes.\n    \"\"\"\n    return os.path.getsize(filename)\n\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# text_prompt = '#Image Classsification using VGG16 model\\ndef VGG16_model_architecture(): #making prediction using the model\\ndef model_predict():'\n\ntext_prompt = 'def VGG16_model_architecture()\\n\"\"\"\\nInitialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function\\n\"\"\"\\n\\bdef train_test_split():\\n\\t\"\"\"Split the data X, Y in to train and test data using sklearn\"\"\"\\n\\bdef model_predict():\\n\\t\"\"\"Make prediction using the deep learning model defined above in VGG16_model_architecture function\"\"\"\\n'\n\ngeneration_config = GenerationConfig(max_new_tokens=100, temperature=0.1)\n\ninputs = tokenizer(text_prompt, return_tensors = 'pt')\n\noutput = model.generate(**inputs,\n                       max_new_tokens = 150,\n                       generation_config=generation_config,\n                       pad_token_id = tokenizer.pad_token_id,)\n\noutput = tokenizer.batch_decode(output,\n                          skip_special_tokens=True\n)\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{text_prompt}')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output[0]}')","metadata":{"execution":{"iopub.status.busy":"2023-08-28T20:36:01.119061Z","iopub.execute_input":"2023-08-28T20:36:01.119434Z","iopub.status.idle":"2023-08-28T20:36:10.660540Z","shell.execute_reply.started":"2023-08-28T20:36:01.119400Z","shell.execute_reply":"2023-08-28T20:36:10.659504Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\ndef VGG16_model_architecture()\n\"\"\"\nInitialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function\n\"\"\"\n\bdef train_test_split():\n\t\"\"\"Split the data X, Y in to train and test data using sklearn\"\"\"\n\bdef model_predict():\n\t\"\"\"Make prediction using the deep learning model defined above in VGG16_model_architecture function\"\"\"\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\ndef VGG16_model_architecture()\n\"\"\"\nInitialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function\n\"\"\"\n\bdef train_test_split():\n\t\"\"\"Split the data X, Y in to train and test data using sklearn\"\"\"\n\bdef model_predict():\n\t\"\"\"Make prediction using the deep learning model defined above in VGG16_model_architecture function\"\"\"\n\t# Load the data\n\tX_train, X_test, Y_train, Y_test = load_data()\n\t# Split the data into training and test sets\n\tX_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n\t# Fit the model\n\tmodel = VGG16_model_architecture()\n\tmodel.fit(X_train, Y_train)\n\t# Predict the labels\n\ty_pred = model.predict(X_test)\n\t# Predict the labels\n\ty_pred =\n","output_type":"stream"}]},{"cell_type":"code","source":"# text_prompt = '#Image Classsification using VGG16 model\\ndef VGG16_model_architecture(): #making prediction using the model\\ndef model_predict():'\n\ntext_prompt = 'def VGG16_model_architecture()\\n\"\"\"\\nInitialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function\\n\"\"\"\\n\\bdef train_test_split():\\n\\t\"\"\"Split the data X, Y in to train and test data using sklearn\"\"\"\\n\\bdef model_predict():\\n\\t\"\"\"Make prediction using the deep learning model defined above in VGG16_model_architecture function\"\"\"\\n'\n\ninputs = tokenizer(text_prompt, return_tensors = 'pt')\n\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens = 200,\n        pad_token_id = tokenizer.pad_token_id,\n    )[0],\n    skip_special_tokens=True\n)\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{text_prompt}')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output}')","metadata":{"execution":{"iopub.status.busy":"2023-08-28T20:36:10.662019Z","iopub.execute_input":"2023-08-28T20:36:10.663740Z","iopub.status.idle":"2023-08-28T20:36:23.972269Z","shell.execute_reply.started":"2023-08-28T20:36:10.663701Z","shell.execute_reply":"2023-08-28T20:36:23.971393Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\ndef VGG16_model_architecture()\n\"\"\"\nInitialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function\n\"\"\"\n\bdef train_test_split():\n\t\"\"\"Split the data X, Y in to train and test data using sklearn\"\"\"\n\bdef model_predict():\n\t\"\"\"Make prediction using the deep learning model defined above in VGG16_model_architecture function\"\"\"\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\ndef VGG16_model_architecture()\n\"\"\"\nInitialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function\n\"\"\"\n\bdef train_test_split():\n\t\"\"\"Split the data X, Y in to train and test data using sklearn\"\"\"\n\bdef model_predict():\n\t\"\"\"Make prediction using the deep learning model defined above in VGG16_model_architecture function\"\"\"\n\t# Load the data\n\tX_train, X_test, Y_train, Y_test = load_data()\n\t# Split the data into training and test sets\n\tX_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n\t# Fit the model\n\tmodel = VGG16_model_architecture()\n\tmodel.fit(X_train, Y_train)\n\t# Predict the labels\n\ty_pred = model.predict(X_test)\n\t# Predict the labels\n\ty_pred = np.argmax(y_pred, axis=1)\n\t# Predict the labels\n\ty_pred = np.array(y_pred)\n\t# Predict the labels\n\ty_pred = np.argmax(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Best Prompt","metadata":{}},{"cell_type":"code","source":"add_prompt = '<SYSTEM_TASK:>\\nGiven the following code description, write Python code to implement the functionality described below\\n<END_TASK>\\n<USER_TASK:>\\nDescription:\\n'\n\ntext_prompt = 'def VGG16_model_architecture()\\n\"\"\"\\nInitialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function\\n\"\"\"\\n\\bdef train_test_split():\\n\\t\"\"\"Split the data X, Y in to train and test data using sklearn\"\"\"\\n\\bdef model_predict():\\n\\t\"\"\"Make prediction using the deep learning model defined above in VGG16_model_architecture function\"\"\"\\n'\n\nfinal_prompt = add_prompt + text_prompt\n\ninputs = tokenizer(final_prompt, return_tensors = 'pt')\n\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens = 350,\n        pad_token_id = tokenizer.pad_token_id,\n    )[0],\n    skip_special_tokens=True\n)\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{text_prompt}')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output}')","metadata":{"execution":{"iopub.status.busy":"2023-08-28T20:36:23.976286Z","iopub.execute_input":"2023-08-28T20:36:23.978776Z","iopub.status.idle":"2023-08-28T20:36:46.075667Z","shell.execute_reply.started":"2023-08-28T20:36:23.978739Z","shell.execute_reply":"2023-08-28T20:36:46.074661Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\ndef VGG16_model_architecture()\n\"\"\"\nInitialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function\n\"\"\"\n\bdef train_test_split():\n\t\"\"\"Split the data X, Y in to train and test data using sklearn\"\"\"\n\bdef model_predict():\n\t\"\"\"Make prediction using the deep learning model defined above in VGG16_model_architecture function\"\"\"\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n\nGiven the following code description, write Python code to implement the functionality described below\n\n\nDescription:\ndef VGG16_model_architecture()\n\"\"\"\nInitialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function\n\"\"\"\n\bdef train_test_split():\n\t\"\"\"Split the data X, Y in to train and test data using sklearn\"\"\"\n\bdef model_predict():\n\t\"\"\"Make prediction using the deep learning model defined above in VGG16_model_architecture function\"\"\"\n\t# Load the data\n\tX_train, X_test, Y_train, Y_test = load_data()\n\t# Split the data into training and test sets\n\tX_train_train, X_test_train, Y_train_train, Y_test_train = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n\t# Split the data into testing and training sets\n\tX_test_test, X_train_test, Y_test_test, Y_train_test = test_split(X_test, Y_test, test_size=0.2, random_state=42)\n\t# Create the model\n\tmodel = VGG16_model(input_shape=X_train_train.shape[1:], output_shape=Y_train_train.shape[1:], weights_path=Y_train_train.shape[1:], weights_name=Y_train_train.name)\n\t# Fit the model\n\tmodel.fit(X_train_train, Y_train_train, batch_size=BATCH_SIZE, nb_epoch=NB_EPOCH, verbose=1, validation_data=(X_test_test, Y_test_test))\n\t# Evaluate the model\n\tscore = model.evaluate(X_test_test, Y_test_test, verbose=0)\n\tprint('Test score:', score[0])\n\tprint('Test accuracy:', score[1])\n\tprint('Test F1 score:', score[\n","output_type":"stream"}]},{"cell_type":"code","source":"add_prompt = \"<SYSTEM_TASK:>\\nCodeParrot, I'd like you to write a Python code snippet to implement the functionality described below\\n<END_TASK>\\n<USER_TASK:>\\nDescription:\\n\"\n\n\ntext_prompt = 'def VGG16_model_architecture()\\n\"\"\"\\nInitialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function\\n\"\"\"\\n\\bdef train_test_split():\\n\\t\"\"\"Split the data X, Y in to train and test data using sklearn\"\"\"\\n\\bdef model_predict():\\n\\t\"\"\"Make prediction using the deep learning model defined above in VGG16_model_architecture function\"\"\"\\n'\n\nfinal_prompt = add_prompt + text_prompt\n\ninputs = tokenizer(final_prompt, return_tensors = 'pt')\n\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens = 200,\n        pad_token_id = tokenizer.pad_token_id,\n    )[0],\n    skip_special_tokens=True\n)\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{text_prompt}')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output}')","metadata":{"execution":{"iopub.status.busy":"2023-08-28T20:36:46.077223Z","iopub.execute_input":"2023-08-28T20:36:46.077605Z","iopub.status.idle":"2023-08-28T20:36:59.295360Z","shell.execute_reply.started":"2023-08-28T20:36:46.077570Z","shell.execute_reply":"2023-08-28T20:36:59.294299Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\ndef VGG16_model_architecture()\n\"\"\"\nInitialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function\n\"\"\"\n\bdef train_test_split():\n\t\"\"\"Split the data X, Y in to train and test data using sklearn\"\"\"\n\bdef model_predict():\n\t\"\"\"Make prediction using the deep learning model defined above in VGG16_model_architecture function\"\"\"\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n\nCodeParrot, I'd like you to write a Python code snippet to implement the functionality described below\n\n\nDescription:\ndef VGG16_model_architecture()\n\"\"\"\nInitialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function\n\"\"\"\n\bdef train_test_split():\n\t\"\"\"Split the data X, Y in to train and test data using sklearn\"\"\"\n\bdef model_predict():\n\t\"\"\"Make prediction using the deep learning model defined above in VGG16_model_architecture function\"\"\"\n\tX_train, X_test, Y_train, Y_test = train_test_split()\n\tmodel = VGG16_model(X_train, Y_train)\n\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\treturn model\n\n\"\"\"\nVGG16_model_architecture()\n\"\"\"\nVGG16_model_architecture()\n\"\"\"\nVGG16_model_architecture()\n\"\"\"\nVGG16_model_architecture()\n\"\"\"\nVGG16_model_architecture()\n\"\"\"\nVGG16_model_architecture()\n\"\"\"\nVGG16_model_architecture()\n\"\"\"\nVGG16_model_architecture()\n\"\"\"\nVGG16_model_architecture()\n\"\"\"\nVGG16_model_architecture()\n\"\"\"\nVGG16_model_architecture()\n\"\"\"\nVGG16_model_architecture()\n","output_type":"stream"}]},{"cell_type":"code","source":"add_prompt = \"<SYSTEM_TASK:>\\nCodeParrot, I'd like you to write a Python code snippet to implement the functionality described below\\n<END_TASK>\\n<USER_TASK:>\\nDescription:\\n\"\n\n\ntext_prompt = 'def Initialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function():\\n\\t\\n\\bdef Split the data X, Y in to train and test data using sklearn():\\n\\t\\n\\bdef Make prediction using the deep learning model defined above in VGG16_model_architecture function():\\n'\n\nfinal_prompt = text_prompt\n\ninputs = tokenizer(final_prompt, return_tensors = 'pt')\n\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens = 200,\n        pad_token_id = tokenizer.pad_token_id,\n    )[0],\n    skip_special_tokens=True\n)\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{text_prompt}')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output}')","metadata":{"execution":{"iopub.status.busy":"2023-08-28T20:36:59.296634Z","iopub.execute_input":"2023-08-28T20:36:59.297705Z","iopub.status.idle":"2023-08-28T20:37:12.094103Z","shell.execute_reply.started":"2023-08-28T20:36:59.297670Z","shell.execute_reply":"2023-08-28T20:37:12.092048Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\ndef Initialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function():\n\t\n\bdef Split the data X, Y in to train and test data using sklearn():\n\t\n\bdef Make prediction using the deep learning model defined above in VGG16_model_architecture function():\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\ndef Initialize VGG16 model a deep learning model trained on imagenet for performing Image Classification in the VGG16_model_architecture function():\n\t\n\bdef Split the data X, Y in to train and test data using sklearn():\n\t\n\bdef Make prediction using the deep learning model defined above in VGG16_model_architecture function():\n\n\u0001def Make prediction using the deep learning model defined above in VGG16_model_architecture function():\n\n\u0001def Make prediction using the deep learning model defined above in VGG16_model_architecture function():\n\n\u0001def Make prediction using the deep learning model defined above in VGG16_model_architecture function():\n\n\u0001def Make prediction using the deep learning model defined above in VGG16_model_architecture function():\n\n\u0001def Make prediction using the deep learning model defined above in VGG16_model_architecture function():\n\n\u0001def Make prediction using the deep learning model defined above in VGG16_model_architecture function():\n\n\u0001def Make prediction using the deep learning model defined above in VGG16_model_architecture function():\n\n\u0001def Make prediction using the deep learning model defined above in VGG16_model_architecture function():\n\n\u0001def Make prediction using the deep learning model defined above in VGG16\n","output_type":"stream"}]}]}